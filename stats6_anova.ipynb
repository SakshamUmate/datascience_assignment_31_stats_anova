{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions Required to Use ANOVA\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means across multiple groups. For the results of an ANOVA to be valid, certain assumptions must be met:\n",
    "\n",
    "1. **Independence of Observations**:\n",
    "   - Each observation should be independent of others.\n",
    "   - **Violation Example**: In a study where participants are measured multiple times, the observations are not independent.\n",
    "\n",
    "2. **Normality**:\n",
    "   - The data in each group should be approximately normally distributed.\n",
    "   - **Violation Example**: If the data in one group is heavily skewed, the normality assumption is violated.\n",
    "\n",
    "3. **Homogeneity of Variances (Homoscedasticity)**:\n",
    "   - The variances among the groups should be approximately equal.\n",
    "   - **Violation Example**: If one group's variance is much larger or smaller than the others, this assumption is violated.\n",
    "\n",
    "4. **Random Sampling**:\n",
    "   - The data should be collected from a random sample of the population.\n",
    "   - **Violation Example**: If a convenience sample is used instead of a random sample, this assumption is violated.\n",
    "\n",
    "### Examples of Violations and Their Impact\n",
    "\n",
    "1. **Independence of Observations**:\n",
    "   - **Example**: In a classroom study where students' test scores are used, scores of students from the same group or classroom may not be independent.\n",
    "   - **Impact**: Violation of this assumption can lead to incorrect conclusions because the ANOVA test assumes that each data point is independent.\n",
    "\n",
    "2. **Normality**:\n",
    "   - **Example**: In a medical study measuring blood pressure, if the data for one group is highly skewed due to an outlier, this assumption is violated.\n",
    "   - **Impact**: Non-normal data can affect the Type I error rate, making it more likely to incorrectly reject the null hypothesis.\n",
    "\n",
    "3. **Homogeneity of Variances**:\n",
    "   - **Example**: In an educational study comparing test scores across different schools, if one school has much more variability in scores than others, this assumption is violated.\n",
    "   - **Impact**: Unequal variances can lead to an increased Type I error rate, affecting the reliability of the test results.\n",
    "\n",
    "4. **Random Sampling**:\n",
    "   - **Example**: In a market research study, if participants are selected based on convenience rather than randomly, this assumption is violated.\n",
    "   - **Impact**: Non-random sampling can introduce bias, making it difficult to generalize the results to the broader population.\n",
    "\n",
    "### How to Check for Assumptions\n",
    "\n",
    "1. **Independence**:\n",
    "   - This is usually determined by the study design.\n",
    "   - Ensure the data collection process is structured to avoid dependency among observations.\n",
    "\n",
    "2. **Normality**:\n",
    "   - Use graphical methods such as Q-Q plots or statistical tests like the Shapiro-Wilk test to check for normality.\n",
    "\n",
    "3. **Homogeneity of Variances**:\n",
    "   - Use Levene's test or Bartlett's test to assess the equality of variances.\n",
    "\n",
    "4. **Random Sampling**:\n",
    "   - Ensure the sampling method used is truly random and representative of the population.\n",
    "\n",
    "### What to Do if Assumptions are Violated\n",
    "\n",
    "1. **Independence**:\n",
    "   - Use a different statistical method that accounts for dependencies, such as mixed-effects models.\n",
    "\n",
    "2. **Normality**:\n",
    "   - Transform the data (e.g., log transformation) or use non-parametric tests like the Kruskal-Wallis test.\n",
    "\n",
    "3. **Homogeneity of Variances**:\n",
    "   - Use a different test such as Welch's ANOVA, which does not assume equal variances.\n",
    "\n",
    "4. **Random Sampling**:\n",
    "   - Improve the sampling method or use caution when interpreting the results, acknowledging the potential bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of ANOVA and Their Uses\n",
    "\n",
    "### Main Points:\n",
    "\n",
    "1. **One-Way ANOVA**\n",
    "   - Compares means of three or more independent groups based on one independent variable.\n",
    "   - Used when there is one categorical independent variable with three or more levels (groups) and one continuous dependent variable.\n",
    "   - Example: Comparing test scores of students from different teaching methods.\n",
    "\n",
    "2. **Two-Way ANOVA**\n",
    "   - Compares means of groups based on two independent variables and assesses the interaction effect between them.\n",
    "   - Used when there are two categorical independent variables and one continuous dependent variable.\n",
    "   - Example: Studying effects of different diets and exercise routines on weight loss.\n",
    "\n",
    "3. **Repeated Measures ANOVA**\n",
    "   - Used when the same subjects are measured multiple times under different conditions.\n",
    "   - Used when there is one categorical independent variable with repeated measures and one continuous dependent variable.\n",
    "   - Example: Measuring blood pressure of patients at different times after administering a drug.\n",
    "\n",
    "### Summary Table:\n",
    "\n",
    "| Type of ANOVA          | Number of Independent Variables | Situation Example                             |\n",
    "|------------------------|---------------------------------|----------------------------------------------|\n",
    "| One-Way ANOVA          | 1                               | Comparing test scores from different teaching methods |\n",
    "| Two-Way ANOVA          | 2                               | Studying the effects of different diets and exercise routines on weight loss |\n",
    "| Repeated Measures ANOVA| 1 (with repeated measures)      | Measuring blood pressure of patients at different times after administering a drug |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning of Variance in ANOVA\n",
    "\n",
    "### What is Partitioning of Variance?\n",
    "\n",
    "Partitioning of variance in ANOVA involves breaking down the total variability in the data into different components attributable to different sources. This process helps in understanding how much of the total variability is explained by the factors being studied and how much is due to random error.\n",
    "\n",
    "### Components of Variance\n",
    "\n",
    "1. **Total Sum of Squares (SST)**\n",
    "   - Represents the total variability in the data.\n",
    "   - Calculated as the sum of the squared differences between each observation and the overall mean.\n",
    "   - Formula: \n",
    "     \\[\n",
    "     $\\text{SST} = \\sum_{i=1}^{N} (X_i - \\bar{X})^2$\n",
    "     \\]\n",
    "\n",
    "2. **Between-Group Sum of Squares (SSB)**\n",
    "   - Represents the variability due to the differences between group means.\n",
    "   - Calculated as the sum of the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "   - Formula: \n",
    "     \\[\n",
    "     $\\text{SSB} = \\sum_{j=1}^{k} n_j (\\bar{X}_j - \\bar{X})^2$\n",
    "     \\]\n",
    "\n",
    "3. **Within-Group Sum of Squares (SSW)**\n",
    "   - Represents the variability within each group.\n",
    "   - Calculated as the sum of the squared differences between each observation and its respective group mean.\n",
    "   - Formula: \n",
    "     \\[\n",
    "     $\\text{SSW} = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (X_{ij} - \\bar{X}_j)^2$\n",
    "     \\]\n",
    "\n",
    "### Importance of Understanding Partitioning of Variance\n",
    "\n",
    "1. **Identifying Sources of Variability**\n",
    "   - Helps in determining how much of the total variability is due to differences between groups (explained variability) and how much is due to random error (unexplained variability).\n",
    "\n",
    "2. **Hypothesis Testing**\n",
    "   - The partitioning of variance is crucial for conducting hypothesis tests in ANOVA. It allows for the calculation of the F-statistic, which is used to test if the group means are significantly different.\n",
    "\n",
    "3. **Interpreting Results**\n",
    "   - Understanding the proportion of total variability explained by the factors being studied (effect size) can provide insights into the strength and importance of the factors.\n",
    "\n",
    "4. **Model Assessment**\n",
    "   - Helps in assessing the goodness of fit of the model. A large between-group sum of squares relative to the within-group sum of squares indicates that the model explains a significant portion of the variability in the data.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Total Sum of Squares (SST)**: Total variability in the data.\n",
    "- **Between-Group Sum of Squares (SSB)**: Variability due to differences between group means.\n",
    "- **Within-Group Sum of Squares (SSW)**: Variability within each group.\n",
    "\n",
    "Understanding the partitioning of variance is essential for conducting ANOVA, interpreting the results, and assessing the significance and impact of the factors being studied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can follow these steps:\n",
    "\n",
    "- Total Sum of Squares (SST): Measures the total variation in the data.\n",
    "- Explained Sum of Squares (SSE): Measures the variation explained by the groups (also known as sum of squares between groups).\n",
    "- Residual Sum of Squares (SSR): Measures the variation within the groups (also known as sum of squares within groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 443.33333333333337\n",
      "Explained Sum of Squares (SSE): 298.13333333333355\n",
      "Residual Sum of Squares (SSR): 145.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data for three groups\n",
    "group1 = np.array([23, 25, 27, 30, 22])\n",
    "group2 = np.array([31, 29, 27, 36, 38])\n",
    "group3 = np.array([19, 20, 23, 21, 24])\n",
    "\n",
    "# Combine all groups into a single array\n",
    "all_groups = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Overall mean\n",
    "overall_mean = np.mean(all_groups)\n",
    "\n",
    "# Group means\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "mean_group3 = np.mean(group3)\n",
    "\n",
    "# Total sum of squares (SST)\n",
    "sst = np.sum((all_groups - overall_mean) ** 2)\n",
    "\n",
    "# Explained sum of squares (SSE)\n",
    "sse = (len(group1) * (mean_group1 - overall_mean) ** 2 +\n",
    "       len(group2) * (mean_group2 - overall_mean) ** 2 +\n",
    "       len(group3) * (mean_group3 - overall_mean) ** 2)\n",
    "\n",
    "# Residual sum of squares (SSR)\n",
    "ssr = (np.sum((group1 - mean_group1) ** 2) +\n",
    "       np.sum((group2 - mean_group2) ** 2) +\n",
    "       np.sum((group3 - mean_group3) ** 2))\n",
    "\n",
    "print(f'Total Sum of Squares (SST): {sst}')\n",
    "print(f'Explained Sum of Squares (SSE): {sse}')\n",
    "print(f'Residual Sum of Squares (SSR): {ssr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Way ANOVA: Calculating Main Effects and Interaction Effects Using Python\n",
    "\n",
    "In a two-way ANOVA, the goal is to assess the main effects of two independent variables and their interaction effect on a dependent variable. Here's how you can calculate these effects using Python:\n",
    "\n",
    "1. **Main Effects**: The effect of each independent variable on the dependent variable.\n",
    "2. **Interaction Effect**: The combined effect of the two independent variables on the dependent variable.\n",
    "\n",
    "We'll use the `statsmodels` library, which provides tools for conducting ANOVA.\n",
    "\n",
    "First, install the `statsmodels` library if you haven't already:\n",
    "\n",
    "```bash\n",
    "pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df          F        PR(>F)\n",
      "C(FactorA)                0.2   1.0   0.058394  8.121220e-01\n",
      "C(FactorB)              320.0   1.0  93.430657  4.397672e-08\n",
      "C(FactorA):C(FactorB)     3.2   1.0   0.934307  3.481307e-01\n",
      "Residual                 54.8  16.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "# Suppose we have two factors: Factor A (with levels A1, A2) and Factor B (with levels B1, B2)\n",
    "# and a dependent variable (DV)\n",
    "data = {\n",
    "    'FactorA': np.repeat(['A1', 'A2'], 10),\n",
    "    'FactorB': np.tile(np.repeat(['B1', 'B2'], 5), 2),\n",
    "    'DV': [10, 15, 14, 10, 12, 20, 23, 21, 19, 22, 12, 14, 13, 11, 16, 21, 22, 20, 18, 21]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('DV ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)', data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "#### Data Preparation:\n",
    "\n",
    "We create a dataset with two factors (FactorA and FactorB) and a dependent variable (DV).\n",
    "#### Model Fitting:\n",
    "\n",
    "We use the ols function to fit an ordinary least squares regression model. The formula 'DV ~ C(FactorA) + C(FactorB) + C(FactorA):C(FactorB)' specifies that we want to include main effects for FactorA and FactorB, as well as their interaction effect.\n",
    "#### ANOVA Table:\n",
    "\n",
    "We use sm.stats.anova_lm(model, typ=2) to perform the ANOVA and get the ANOVA table.\n",
    "### Output:\n",
    " The ANOVA table will contain the following columns:\n",
    "- sum_sq: Sum of squares for each source of variation.\n",
    "- df: Degrees of freedom for each source of variation.\n",
    "- F: F-statistic for each source of variation.\n",
    "- PR(>F): p-value for the F-statistic.\n",
    "This table provides information about the main effects of FactorA and FactorB, as well as their interaction effect. The significance of each effect can be determined by examining the p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of One-Way ANOVA Results\n",
    "\n",
    "Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how you can interpret these results:\n",
    "\n",
    "### Hypotheses in One-Way ANOVA\n",
    "\n",
    "- **Null Hypothesis ($H_0$)**: The means of all groups are equal. There are no differences between the groups.\n",
    "- **Alternative Hypothesis ($ H_a $)**: At least one group mean is different from the others.\n",
    "\n",
    "### F-Statistic and P-Value\n",
    "\n",
    "- **F-Statistic (5.23)**: This value indicates the ratio of the variance between the group means to the variance within the groups. A higher F-statistic suggests greater variability between group means compared to within-group variability.\n",
    "- **P-Value (0.02)**: The p-value indicates the probability of observing an F-statistic as extreme as 5.23, assuming the null hypothesis is true. A lower p-value suggests stronger evidence against the null hypothesis.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Significance Level ($\\alpha$)**: Commonly, a significance level of 0.05 is used.\n",
    "- **P-Value Comparison**: The obtained p-value (0.02) is less than the significance level (0.05).\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Since the p-value (0.02) is less than 0.05, we reject the null hypothesis. This means there is statistically significant evidence to conclude that there are differences between the group means. In other words, at least one group mean is significantly different from the others.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Post-Hoc Tests**: To determine which specific groups differ from each other, you can perform post-hoc tests such as Tukey's HSD (Honestly Significant Difference) test.\n",
    "- **Effect Size**: Consider calculating the effect size (e.g., eta squared) to understand the magnitude of the differences between groups.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The one-way ANOVA results indicate that there are significant differences between the group means, given an F-statistic of 5.23 and a p-value of 0.02. Further analysis through post-hoc tests can help identify the specific groups that differ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data in Repeated Measures ANOVA\n",
    "\n",
    "In a repeated measures ANOVA, missing data can be a challenge because the same subjects are measured under different conditions or over time. Handling missing data appropriately is crucial to maintaining the integrity of the analysis.\n",
    "\n",
    "### Methods to Handle Missing Data\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**\n",
    "    - **Description**: Exclude any subject with missing data from the analysis.\n",
    "    - **Pros**: Simple to implement; maintains consistency in sample size across measurements.\n",
    "    - **Cons**: Reduces sample size and statistical power; can introduce bias if the missing data are not completely random.\n",
    "\n",
    "2. **Pairwise Deletion**\n",
    "    - **Description**: Use all available data by excluding missing data on a case-by-case basis.\n",
    "    - **Pros**: Uses more data compared to listwise deletion; can be more efficient.\n",
    "    - **Cons**: Can lead to inconsistencies in the analysis; more complex to implement and interpret.\n",
    "\n",
    "3. **Mean Imputation**\n",
    "    - **Description**: Replace missing values with the mean of the observed values for that variable.\n",
    "    - **Pros**: Simple to implement; retains all subjects in the analysis.\n",
    "    - **Cons**: Underestimates variability; can bias parameter estimates downward.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)**\n",
    "    - **Description**: Replace missing values with the last observed value for that subject.\n",
    "    - **Pros**: Retains all subjects in the analysis; useful in longitudinal studies.\n",
    "    - **Cons**: Assumes stability of the variable over time; can bias results if this assumption is not met.\n",
    "\n",
    "5. **Multiple Imputation**\n",
    "    - **Description**: Replace missing values with multiple sets of simulated values to create several complete datasets, analyze each one, and then combine the results.\n",
    "    - **Pros**: Accounts for uncertainty in the imputation process; provides more accurate standard errors and confidence intervals.\n",
    "    - **Cons**: Computationally intensive; requires more advanced statistical knowledge and software.\n",
    "\n",
    "6. **Maximum Likelihood Estimation (MLE)**\n",
    "    - **Description**: Use all available data to estimate the model parameters directly.\n",
    "    - **Pros**: Efficient use of all data; provides unbiased estimates under the assumption of missing at random (MAR).\n",
    "    - **Cons**: Requires sophisticated software and understanding of likelihood-based methods.\n",
    "\n",
    "### Potential Consequences of Different Methods\n",
    "\n",
    "1. **Listwise Deletion**: Reduces the sample size, which can lead to a loss of statistical power and potentially biased results if the data are not missing completely at random (MCAR).\n",
    "\n",
    "2. **Pairwise Deletion**: Can introduce inconsistencies in sample size across different analyses, complicating interpretation and possibly leading to biased results.\n",
    "\n",
    "3. **Mean Imputation**: Reduces variability and can bias parameter estimates downward, potentially leading to incorrect conclusions.\n",
    "\n",
    "4. **LOCF**: Assumes no change over time, which can lead to biased results if the assumption is incorrect. It can also underestimate variability.\n",
    "\n",
    "5. **Multiple Imputation**: More accurate and robust, but computationally intensive and requires more advanced statistical knowledge.\n",
    "\n",
    "6. **Maximum Likelihood Estimation**: Efficient and unbiased under the MAR assumption but requires sophisticated software and statistical understanding.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- **Assess Missing Data Mechanism**: Before choosing a method, assess the pattern and mechanism of the missing data (e.g., MCAR, MAR, or not missing at random (NMAR)).\n",
    "- **Use Advanced Methods**: If possible, prefer multiple imputation or MLE, as they provide more accurate and reliable results by accounting for the uncertainty in the missing data.\n",
    "- **Sensitivity Analysis**: Perform sensitivity analyses to check how different methods of handling missing data affect the results.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Handling missing data in repeated measures ANOVA is crucial for maintaining the validity of the analysis. Different methods have various pros and cons, and the choice of method can significantly impact the results. Advanced methods like multiple imputation or maximum likelihood estimation are generally preferred for their accuracy and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Post-Hoc Tests Used After ANOVA\n",
    "\n",
    "Post-hoc tests are performed after an ANOVA when the null hypothesis is rejected, indicating that at least one group mean is different from the others. These tests help determine which specific groups differ from each other. Here are some common post-hoc tests and when to use them:\n",
    "\n",
    "### 1. Tukey's Honestly Significant Difference (HSD) Test\n",
    "- **Use Case**: When you want to compare all possible pairs of group means.\n",
    "- **Assumptions**: Equal variances and sample sizes, although robust to minor deviations.\n",
    "- **Example**: Comparing the effectiveness of different teaching methods (e.g., traditional, online, hybrid) on student performance.\n",
    "\n",
    "### 2. Bonferroni Correction\n",
    "- **Use Case**: When you want to control the family-wise error rate by adjusting the significance level.\n",
    "- **Assumptions**: Same as the original ANOVA test.\n",
    "- **Example**: Multiple comparisons in a clinical trial where several treatments are tested against a control.\n",
    "\n",
    "### 3. Scheffé's Method\n",
    "- **Use Case**: When you need a more conservative test that can handle unequal sample sizes and variances.\n",
    "- **Assumptions**: Suitable for complex comparisons involving linear combinations of group means.\n",
    "- **Example**: Comparing different diet plans on weight loss where variances and sample sizes might differ.\n",
    "\n",
    "### 4. Dunnett's Test\n",
    "- **Use Case**: When comparing multiple treatment groups to a single control group.\n",
    "- **Assumptions**: Assumes equal variances across groups.\n",
    "- **Example**: Testing new drug formulations against a standard control drug.\n",
    "\n",
    "### 5. Holm's Sequential Bonferroni Procedure\n",
    "- **Use Case**: When you need a stepwise method to control the family-wise error rate.\n",
    "- **Assumptions**: Similar to the Bonferroni correction.\n",
    "- **Example**: Comparing different fertilizer types on plant growth.\n",
    "\n",
    "### 6. Fisher's Least Significant Difference (LSD) Test\n",
    "- **Use Case**: When you want to perform multiple comparisons without adjusting for multiple testing (more liberal approach).\n",
    "- **Assumptions**: Equal variances and normally distributed errors.\n",
    "- **Example**: Initial screening of potential factors affecting product quality in a manufacturing process.\n",
    "\n",
    "### Example Situation\n",
    "\n",
    "Suppose you conducted an ANOVA to evaluate the effectiveness of different study techniques (Group A: Flashcards, Group B: Highlighting, Group C: Summarization, Group D: Rereading) on exam scores. The ANOVA results show a significant difference between the groups (p-value < 0.05). To determine which specific groups differ, you can perform a post-hoc test.\n",
    "\n",
    "### Performing Tukey's HSD Test in Python\n",
    "\n",
    "Here's how you can ups=df['StudyTechnique'], alpha=0.05)\n",
    "\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Multiple Comparison of Means - Tukey HSD, FWER=0.05        \n",
      "==================================================================\n",
      "   group1        group2    meandiff p-adj   lower    upper  reject\n",
      "------------------------------------------------------------------\n",
      "  Flashcards  Highlighting     -4.6 0.0026  -7.8319 -1.3681   True\n",
      "  Flashcards     Rereading    -10.4    0.0 -13.6319 -7.1681   True\n",
      "  Flashcards Summarization      4.0 0.0103   0.7681  7.2319   True\n",
      "Highlighting     Rereading     -5.8 0.0001  -9.0319 -2.5681   True\n",
      "Highlighting Summarization      8.6    0.0   5.3681 11.8319   True\n",
      "   Rereading Summarization     14.4    0.0  11.1681 17.6319   True\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'StudyTechnique': np.repeat(['Flashcards', 'Highlighting', 'Summarization', 'Rereading'], 10),\n",
    "    'ExamScore': [78, 85, 84, 79, 88, 85, 82, 86, 87, 84, 75, 73, 78, 77, 80, 79, 82, 81, 83, 84,\n",
    "                  88, 85, 87, 86, 90, 88, 87, 89, 88, 90, 72, 70, 75, 74, 73, 75, 74, 76, 73, 72]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(endog=df['ExamScore'], groups=df['StudyTechnique'], alpha=0.05)\n",
    "\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Pytho \n",
    "to determine if there are any significant differences between the mean weight loss of the three diet .\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Way ANOVA: Comparing Mean Weight Loss of Three Diets\n",
    "\n",
    "A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. We'll conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "### Step-by-Step Process\n",
    "\n",
    "1. **Import Libraries**: We'll use `pandas`, `numpy`, and `statsmodels` for the analysis.\n",
    "2. **Prepare Data**: Create a dataset with the weight loss data for the three diets.\n",
    "3. **Fit ANOVA Model**: Use `statsmodels` to fit the ANOVA model.\n",
    "4. **Perform ANOVA**: Get the ANOVA table and extract the F-statistic and p-value.\n",
    "5. **Interpret Results**: Determine if there are significant differences between the diets.\n",
    "\n",
    "### int the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sum_sq    df         F    PR(>F)\n",
      "C(Diet)    37.529415   2.0  7.175732  0.001907\n",
      "Residual  122.906107  47.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(0)\n",
    "diet_A = np.random.normal(loc=5, scale=1.5, size=17)  # Mean weight loss = 5, SD = 1.5\n",
    "diet_B = np.random.normal(loc=6, scale=1.5, size=17)  # Mean weight loss = 6, SD = 1.5\n",
    "diet_C = np.random.normal(loc=4.5, scale=1.5, size=16)  # Mean weight loss = 4.5, SD = 1.5\n",
    "\n",
    "# Combine data into a DataFrame\n",
    "data = {\n",
    "    'WeightLoss': np.concatenate([diet_A, diet_B, diet_C]),\n",
    "    'Diet': ['A'] * 17 + ['B'] * 17 + ['C'] * 16\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the one-way ANOVA model\n",
    "model = ols('WeightLoss ~ C(Diet)', data=df).fit()\n",
    "\n",
    "# Perform the ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The F-statistic is 7.1757, and the p-value is 0.0019. Since the p-value is less than the common significance level of 0.05, we reject the null hypothesis. This indicates that there are significant differences in mean weight loss among the three diets.\n",
    "\n",
    "### Conclusion\n",
    "The one-way ANOVA results suggest that the mean weight loss differs significantly between at least two of the diets (A, B, and C). To determine which specific diets differ, a post-hoc test such as Tukey's HSD can be performed.\n",
    "\n",
    "### Performing Post-Hoc Test (Tukey's HSD)\n",
    "To identify which specific diets differ, you can perform Tukey's HSD test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B  -0.1749 0.9467 -1.5172  1.1674  False\n",
      "     A      C  -1.9383 0.0034 -3.3014 -0.5751   True\n",
      "     B      C  -1.7634 0.0083 -3.1265 -0.4002   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(endog=df['WeightLoss'], groups=df['Diet'], alpha=0.05)\n",
    "\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "By conducting a one-way ANOVA, we found significant differences in mean weight loss between the three diets. The F-statistic was 7.1757, and the p-value was 0.0019. A post-hoc test like Tukey's HSD can be used to identify which specific diets have different mean weight losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### To conduct a two-way ANOVA using Python, we'll follow these steps:\n",
    "\n",
    "- **Create a synthetic dataset:** We will simulate data for 30 employees using three different software programs and classify them as novice or experienced.\n",
    "- **Perform the two-way ANOVA:** We will use the statsmodels library to perform the two-way ANOVA and analyze the main effects and interaction effects.\n",
    "- **Interpret the results:** We'll report the F-statistics and p-values and interpret them.\n",
    "### Step 1: Create a synthetic dataset\n",
    "Let's create a synthetic dataset where 30 employees are randomly assigned to one of three software programs and classified as novice or experienced. We'll also generate random task completion times for each combination of software and experience level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee</th>\n",
       "      <th>Program</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Program C</td>\n",
       "      <td>Experienced</td>\n",
       "      <td>43.993613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Program A</td>\n",
       "      <td>Experienced</td>\n",
       "      <td>42.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Program C</td>\n",
       "      <td>Experienced</td>\n",
       "      <td>43.982934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Program C</td>\n",
       "      <td>Experienced</td>\n",
       "      <td>68.522782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Program A</td>\n",
       "      <td>Experienced</td>\n",
       "      <td>44.865028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee    Program   Experience       Time\n",
       "0         1  Program C  Experienced  43.993613\n",
       "1         2  Program A  Experienced  42.083063\n",
       "2         3  Program C  Experienced  43.982934\n",
       "3         4  Program C  Experienced  68.522782\n",
       "4         5  Program A  Experienced  44.865028"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    'Employee': np.arange(1, 31),\n",
    "    'Program': np.random.choice(['Program A', 'Program B', 'Program C'], 30),\n",
    "    'Experience': np.random.choice(['Novice', 'Experienced'], 30),\n",
    "    'Time': np.random.normal(loc=50, scale=10, size=30)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adjust task completion times for interaction effects\n",
    "for i in df.index:\n",
    "    if df.loc[i, 'Program'] == 'Program A':\n",
    "        df.loc[i, 'Time'] += 5 if df.loc[i, 'Experience'] == 'Novice' else -5\n",
    "    elif df.loc[i, 'Program'] == 'Program B':\n",
    "        df.loc[i, 'Time'] += 3 if df.loc[i, 'Experience'] == 'Novice' else -3\n",
    "    else:  # Program C\n",
    "        df.loc[i, 'Time'] += 0 if df.loc[i, 'Experience'] == 'Novice' else 0\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perform the two-way ANOVA\n",
    "We will use the statsmodels library to perform the two-way ANOVA and analyze the main effects and interaction effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Program)</th>\n",
       "      <td>63.506916</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.336109</td>\n",
       "      <td>0.717855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Experience)</th>\n",
       "      <td>117.699761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.245847</td>\n",
       "      <td>0.275398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Program):C(Experience)</th>\n",
       "      <td>221.449736</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.172018</td>\n",
       "      <td>0.326849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>2267.368865</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sum_sq    df         F    PR(>F)\n",
       "C(Program)                  63.506916   2.0  0.336109  0.717855\n",
       "C(Experience)              117.699761   1.0  1.245847  0.275398\n",
       "C(Program):C(Experience)   221.449736   2.0  1.172018  0.326849\n",
       "Residual                  2267.368865  24.0       NaN       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Fit the model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "anova_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Interpret the results\n",
    "We will report the F-statistics and p-values from the ANOVA table and interpret them.\n",
    "## ANOVA Results\n",
    "\n",
    "\\[\n",
    "$\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Source} & \\text{Sum of Squares} & \\text{Df} & \\text{F-statistic} & \\text{p-value} \\\\\n",
    "\\hline\n",
    "\\text{Program} & 63.506916\t & 2 & 0.336109 & 0.717855 \\\\\n",
    "\\text{Experience} & 117.699761 & 1 & 1.245847 & 0.275398 \\\\\n",
    "\\text{Program:Experience} & 221.449736 & 2 & 1.172018 & 0.326849 \\\\\n",
    "\\text{Residual} & 2267.368865 & 24 & \\text{NA} & \\text{NA} \\\\\n",
    "\\hline\n",
    "\\end{array}$\n",
    "\\]\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The F-statistic for `Program` is 0.34 with a p-value of 0.718, indicating that there is no significant main effect of the software program on task completion time.\n",
    "- The F-statistic for `Experience` is 1.25 with a p-value of 0.275, suggesting that there is no significant main effect of employee experience on task completion time.\n",
    "- The F-statistic for the interaction effect `Program:Experience` is 1.17 with a p-value of 0.327, indicating that there is no significant interaction effect between the software program and employee experience level on task completion time.\n",
    "\n",
    "Based on these results, we conclude that there are no significant differences in the average time it takes to complete a task using the three different software programs, and there is no significant interaction effect between the software programs and employee experience level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To conduct a two-sample t-test in Python, we'll follow these steps:\n",
    "\n",
    "- **Create a synthetic dataset:** Simulate test scores for 100 students assigned to either a control group (traditional teaching method) or an experimental group (new teaching method).\n",
    "- **Perform the two-sample t-test:** Use the scipy.stats library to perform the t-test.\n",
    "- **Interpret the results:** Report the t-statistic and p-value and interpret them.\n",
    "\n",
    "Follow up with a post-hoc test if results are significant: Perform additional analysis to identify which groups differ significantly if the initial test is significant.\n",
    "### Step 1: Create a Synthetic Dataset\n",
    "We'll create a synthetic dataset for 100 students with their test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Group</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Control</td>\n",
       "      <td>82.384666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>81.713683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Control</td>\n",
       "      <td>73.843517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Control</td>\n",
       "      <td>71.988963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Control</td>\n",
       "      <td>60.214780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student         Group      Score\n",
       "0        1       Control  82.384666\n",
       "1        2  Experimental  81.713683\n",
       "2        3       Control  73.843517\n",
       "3        4       Control  71.988963\n",
       "4        5       Control  60.214780"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    'Student': np.arange(1, 101),\n",
    "    'Group': np.random.choice(['Control', 'Experimental'], 100),\n",
    "    'Score': np.random.normal(loc=75, scale=10, size=100)\n",
    "}\n",
    "\n",
    "# Add some differences between groups\n",
    "for i in range(100):\n",
    "    if data['Group'][i] == 'Experimental':\n",
    "        data['Score'][i] += 5\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perform the Two-Sample T-Test\n",
    "We'll use the `scipy.stats` library to perform the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7936665923984396, 0.07595057557272443)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Separate the scores by group\n",
    "control_scores = df[df['Group'] == 'Control']['Score']\n",
    "experimental_scores = df[df['Group'] == 'Experimental']['Score']\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_stat, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "t_stat, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Based on the results of the two-sample t-test:\n",
    "\n",
    "- The t-statistic is approximately -1.79.\n",
    "- The p-value is approximately 0.076.\n",
    "\n",
    "Since the p-value (0.076) is greater than 0.05, we fail to reject the null hypothesis. This indicates that there is no statistically significant difference in test scores between the control group (traditional teaching method) and the experimental group (new teaching method).\n",
    "\n",
    "### Conclusion\n",
    "There are no significant differences in test scores between the two groups based on the provided data. Therefore, no post-hoc test is necessary in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To conduct a repeated measures ANOVA in Python, we'll follow these steps:\n",
    "\n",
    "- **Create a synthetic dataset:** Simulate daily sales data for 30 days for three stores (Store A, Store B, Store C).\n",
    "- **Perform the repeated measures ANOVA:** Use the statsmodels library to perform the analysis.\n",
    "- **Interpret the results:** Report the F-statistic and p-value and interpret them.\n",
    "Follow up with a post-hoc test if results are significant: Use a post-hoc test to determine which store(s) differ significantly if the initial test is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19540\\435569346.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if res.anova_table['Pr > F'][0] < 0.05:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Day     Store_A     Store_B     Store_C\n",
       " 0    1  209.934283  207.965868  200.416515\n",
       " 1    2  197.234714  257.045564  206.286820\n",
       " 2    3  212.953771  219.730056  187.873301\n",
       " 3    4  230.460597  198.845781  186.075868\n",
       " 4    5  195.316933  236.450898  226.250516,\n",
       "          F Value  Num DF  Den DF    Pr > F\n",
       " Store  10.340843     2.0    58.0  0.000144,\n",
       " <class 'statsmodels.iolib.table.SimpleTable'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "days = np.arange(1, 31)\n",
    "store_a_sales = np.random.normal(loc=200, scale=20, size=30)\n",
    "store_b_sales = np.random.normal(loc=220, scale=20, size=30)\n",
    "store_c_sales = np.random.normal(loc=210, scale=20, size=30)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Day': days,\n",
    "    'Store_A': store_a_sales,\n",
    "    'Store_B': store_b_sales,\n",
    "    'Store_C': store_c_sales\n",
    "})\n",
    "\n",
    "# Reshape the DataFrame to long format\n",
    "df_long = pd.melt(df, id_vars=['Day'], value_vars=['Store_A', 'Store_B', 'Store_C'], \n",
    "                var_name='Store', value_name='Sales')\n",
    "\n",
    "# Perform the repeated measures ANOVA\n",
    "aovrm = AnovaRM(df_long, 'Sales', 'Day', within=['Store'])\n",
    "res = aovrm.fit()\n",
    "\n",
    "# Perform the post-hoc test if the results are significant\n",
    "if res.anova_table['Pr > F'][0] < 0.05:\n",
    "    posthoc = pairwise_tukeyhsd(df_long['Sales'], df_long['Store'])\n",
    "    posthoc_results = posthoc.summary()\n",
    "else:\n",
    "    posthoc_results = \"No significant differences found, no post-hoc test needed.\"\n",
    "\n",
    "df.head(), res.anova_table, posthoc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
